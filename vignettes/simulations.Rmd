---
title: "Simulations"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{simulations}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>", fig.align = "center"
)
```

```{r setup}
library(zazou)
library(ape)
```

# Deterministic situation

```{r tree}
tree <- read.tree(text = "(((A,B),C),(D,E));")
tree$tip.label
```

```{r incidence_mat}
incidence_mat <- incidence_matrix(tree)
incidence_mat + 0
```

```{r zscores}
true_shifts <- c(0, -3, 0, 0, 0, 0, -2, 0)
obs_zscores <- true_zscores <- incidence_mat %*% true_shifts
covar_mat <- diag(nrow = 5, ncol = 5)
```


```{r ggtree, message=FALSE}
plot_shifts(tree, true_shifts, true_scores = true_zscores)
```


```{r}
estimation <- estimate_shifts2(rep(0, 8), zscores = obs_zscores, 
                               tree = tree, lambda = 0, 
                               covar_mat = covar_mat)
estimation
plot(estimation)
```

Solution without penalty is not sparse due to ill-conditioning of the incidence matrix. 


```{r}
estimation <- estimate_shifts2(rep(0, 8), zscores = obs_zscores, 
                               tree = tree, lambda = 0.1, 
                               covar_mat = covar_mat)
estimation
plot(estimation)
```

With a low penalty, the solution is much sparser and closer to the true shifts on branches. 

# Simulations on a toy example

```{r ou_correlation_matrix}
tree <- read.tree(text = "(((A:1,B:1):1,C:2):1,(D:1,E:1):2);")
set.seed(2019)
covar_mat <- covariance_matrix(tree, alpha = 1)
corrplot::corrplot(covar_mat, type = "upper")
true_shifts <- c(-3, -3, 0, -2, 0)
sqrtcovar <- t(chol(covar_mat))
zscores <- true_shifts + sqrtcovar %*% rnorm(5) # simulate 
zscores
```

## Estimate shifts without penalty

The fit is perfect since all observed $z$-scores are negative. 

```{r}
estimation <- estimate_shifts2(rep(0, 8), zscores = zscores, tree = tree, alpha = 1, lambda = 0)
estimation
plot(estimation, true_scores = true_shifts)

round(data.frame(true = true_shifts, observed  = zscores,
                 estimated = estimation$zscores_est), 
      digits = 4)
```

The fit degrades as we increase sparsity. [Well, not so much...]

```{r}
estimation <- estimate_shifts2(rep(0, 8), zscores = zscores, tree = tree, alpha = 1, lambda = 0.1)
estimation
plot(estimation, true_scores = true_shifts)

round(data.frame(true = true_shifts, observed  = zscores,
                 estimated = estimation$zscores_est), 
      digits = 4)
```

The fit does not depend a lot (on this toy example) on the initial solution. 

```{r}
estimation <- estimate_shifts2(c(0, -3, 0, 0, 0, 0, -2, 0), 
                               zscores = zscores, tree = tree, 
                               alpha = 1, lambda = 0.1)

estimation
plot(estimation, true_scores = true_shifts)

round(data.frame(true = true_shifts, observed  = zscores,
                 estimated = estimation$zscores_est), 
      digits = 4)
```


# Simulations from real data
 
```{r}
set.seed(42)
data(alcohol)
abund <- alcohol$X[, alcohol$Y == "Low"]
groups <- sample(c("A", "B"), size = ncol(abund), replace = TRUE)
tree <- force_ultrametric(alcohol$tree)
otu_to_kepp <- names(which(rowSums(abund > 0) > 20))
abund <- abund[otu_to_kepp, ]
tree <- phyloseq::prune_taxa(otu_to_kepp, tree)
N_branch <- length(tree$edge.length)
```

```{r}
pvalues_original <- test_wilcoxon(abund, groups)$p.value
zscores_original <- p2z(pvalues_original)
plot_shifts(tree, shifts = NA, obs_scores = zscores_original)
```


```{r}
D <- cophenetic(tree)
obj <- cluster::pam(D, 20)
clustering <- obj$clustering
```


```{r}
clusters <- sample(10, 4)
table(clustering[which(clustering %in% clusters)])
# cluster1 <- names(which(clustering == clusters[1]))
# cluster2 <- names(which(clustering == clusters[2]))
# cluster3 <- names(which(clustering == clusters[3]))
# cluster4 <- names(which(clustering == clusters[4]))
otus_da <- names(clustering[which(clustering %in% clusters)])
abund[otus_da, groups == "B"] <- 4 * abund[otus_da,  groups == "B"]
```


```{r}
pvalues <- test_wilcoxon(abund, groups)$p.value
zscores <- p2z(pvalues)
plot_shifts(tree, NA, obs_scores = zscores)
```


```{r}
plot_shifts(tree, NA, 
            sup_scores = list(list(scores = zscores - zscores_original,
                                   title = "Difference in z-scores after fold-change",
                                   color = "as.character(sign(scores))")))
```


```{r}
estimation <- estimate_shifts3(rep(0, N_branch), zscores = zscores, 
                               lambda = c(0.1, 0.5, 1, 2, 5), tree = tree, alpha = c(0.01, 0.1, 1, 5))
estimation
plot(estimation)
estimation$optim_info$bic_selection
```


```{r}
detected <- names(which(estimation$zscores_est != 0))
detected_bh <- names(which(p.adjust(pvalues, method = "BH") < 0.05))
evabic::ebc_tidy(detected, otus_da, m = length(otu_to_kepp))
evabic::ebc_tidy(detected_bh, otus_da, m = length(otu_to_kepp))
```


